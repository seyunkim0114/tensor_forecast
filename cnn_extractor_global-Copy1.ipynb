{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d22e4e5-acc5-43b0-8c76-8b714173fc29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorly as tl\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import statistics\n",
    "import torch.optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "888e8253-bcdf-470a-837d-f971d4d80990",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lambda(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.func = func\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.func(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f7e01b3-8a92-4efd-b57f-0812bdc1c998",
   "metadata": {},
   "outputs": [],
   "source": [
    "tl.set_backend('numpy')\n",
    "tensor_data = torch.FloatTensor(np.random.rand(1,1,30,500))\n",
    "split = tensor_data.shape[3]//4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23e111e3-3477-4d15-8660-37224670935f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tensor = tensor_data[:,:,:,0:split*2]\n",
    "val_tensor = tensor_data[:,:,:,split*2:split*3]\n",
    "test_tensor = tensor_data[:,:,:,split*3:tensor_data.shape[3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73e579cd-aac5-4de8-b7cc-4d3b8c865f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_Extractor(nn.Module):\n",
    "    def __init__(self, w, R, gKernel, lKernel):\n",
    "        super().__init__()\n",
    "        #self.local_kernel = local_kernel\n",
    "        #self.global_kernel =  global_kernel\n",
    "        self.w = w\n",
    "        self.R = R\n",
    "        self.gKernel = gKernel\n",
    "        self.lKernel = lKernel\n",
    "        self.conv2d_local = nn.Conv2d(1,1,(self.R,self.lKernel)) # 30x1\n",
    "        self.conv2d_global = nn.Conv2d(1,1,(self.R,self.gKernel)) # 30x5\n",
    "        self.fc = nn.Linear(in_features=2*self.w-lKernel-gKernel+2, out_features=self.R) \n",
    "            # Change this number of out_features to forecast longer time\n",
    "            \n",
    "    def forward(self, x):\n",
    "        _local = self.conv2d_local(x)\n",
    "        _global = self.conv2d_global(x)\n",
    "        x = torch.cat((_local,_global),3)\n",
    "        x = self.fc(x)\n",
    "        x = torch.tanh(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4fa3d51d-af4e-415f-b660-c47f46a572d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "learning_rate = 1e-3\n",
    "train_len = train_tensor.shape[3]\n",
    "val_len = val_tensor.shape[3]\n",
    "test_len = test_tensor.shape[3]\n",
    "epochs = 100\n",
    "# Create Model\n",
    "cnn_extractor = CNN_Extractor(10,30,5,1)\n",
    "loss_fnc = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(cnn_extractor.parameters(), lr=learning_rate, momentum=0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1870f3b2-884e-4c7b-8062-f6a6575baf3b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/seyunkim/anaconda3/envs/syenv/lib/python3.6/site-packages/torch/autograd/__init__.py:147: UserWarning: CUDA initialization: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:109.)\n",
      "  allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 0.3072214424610138\t\tEpoch: 0, Val-loss: 0.1617903858423233\n",
      "Epoch: 2, Loss: 0.09003757685422897\t\tEpoch: 2, Val-loss: 0.08740904927253723\n",
      "Epoch: 4, Loss: 0.08792639523744583\t\tEpoch: 4, Val-loss: 0.08662678301334381\n",
      "Epoch: 6, Loss: 0.08709518611431122\t\tEpoch: 6, Val-loss: 0.0859762653708458\n",
      "Epoch: 8, Loss: 0.08641600608825684\t\tEpoch: 8, Val-loss: 0.08543183654546738\n",
      "Epoch: 10, Loss: 0.08585486561059952\t\tEpoch: 10, Val-loss: 0.08498255908489227\n",
      "Epoch: 12, Loss: 0.0853872150182724\t\tEpoch: 12, Val-loss: 0.084610715508461\n",
      "Epoch: 14, Loss: 0.08499405533075333\t\tEpoch: 14, Val-loss: 0.08430179953575134\n",
      "Epoch: 16, Loss: 0.08466073870658875\t\tEpoch: 16, Val-loss: 0.08404428511857986\n",
      "Epoch: 18, Loss: 0.08437579870223999\t\tEpoch: 18, Val-loss: 0.08382895588874817\n",
      "Epoch: 20, Loss: 0.08413026481866837\t\tEpoch: 20, Val-loss: 0.08364846557378769\n",
      "Epoch: 22, Loss: 0.08391702175140381\t\tEpoch: 22, Val-loss: 0.08349687606096268\n",
      "Epoch: 24, Loss: 0.08373041450977325\t\tEpoch: 24, Val-loss: 0.08336934447288513\n",
      "Epoch: 26, Loss: 0.08356589823961258\t\tEpoch: 26, Val-loss: 0.08326198160648346\n",
      "Epoch: 28, Loss: 0.08341982960700989\t\tEpoch: 28, Val-loss: 0.08317158371210098\n",
      "Epoch: 30, Loss: 0.0832892581820488\t\tEpoch: 30, Val-loss: 0.08309546113014221\n",
      "Epoch: 32, Loss: 0.08317173272371292\t\tEpoch: 32, Val-loss: 0.08303149044513702\n",
      "Epoch: 34, Loss: 0.08306530117988586\t\tEpoch: 34, Val-loss: 0.08297787606716156\n",
      "Epoch: 36, Loss: 0.0829683169722557\t\tEpoch: 36, Val-loss: 0.08293308317661285\n",
      "Epoch: 38, Loss: 0.0828794315457344\t\tEpoch: 38, Val-loss: 0.08289588987827301\n",
      "Epoch: 40, Loss: 0.08279751986265182\t\tEpoch: 40, Val-loss: 0.08286525309085846\n",
      "Epoch: 42, Loss: 0.08272162824869156\t\tEpoch: 42, Val-loss: 0.08284028619527817\n",
      "Epoch: 44, Loss: 0.08265095949172974\t\tEpoch: 44, Val-loss: 0.08282025903463364\n",
      "Epoch: 46, Loss: 0.08258485794067383\t\tEpoch: 46, Val-loss: 0.08280454576015472\n",
      "Epoch: 48, Loss: 0.08252273499965668\t\tEpoch: 48, Val-loss: 0.08279261738061905\n",
      "Epoch: 50, Loss: 0.08246409893035889\t\tEpoch: 50, Val-loss: 0.08278404176235199\n",
      "Epoch: 52, Loss: 0.08240856230258942\t\tEpoch: 52, Val-loss: 0.08277839422225952\n",
      "Epoch: 54, Loss: 0.08235575258731842\t\tEpoch: 54, Val-loss: 0.08277539908885956\n",
      "Epoch: 56, Loss: 0.08230535686016083\t\tEpoch: 56, Val-loss: 0.08277471363544464\n",
      "Epoch: 58, Loss: 0.08225709199905396\t\tEpoch: 58, Val-loss: 0.08277614414691925\n",
      "Epoch: 60, Loss: 0.08221074938774109\t\tEpoch: 60, Val-loss: 0.08277946710586548\n",
      "Epoch: 62, Loss: 0.08216612786054611\t\tEpoch: 62, Val-loss: 0.0827844962477684\n",
      "Epoch: 64, Loss: 0.0821230337023735\t\tEpoch: 64, Val-loss: 0.08279107511043549\n",
      "Epoch: 66, Loss: 0.08208131045103073\t\tEpoch: 66, Val-loss: 0.08279906958341599\n",
      "Epoch: 68, Loss: 0.08204082399606705\t\tEpoch: 68, Val-loss: 0.08280836045742035\n",
      "Epoch: 70, Loss: 0.0820014625787735\t\tEpoch: 70, Val-loss: 0.08281882852315903\n",
      "Epoch: 72, Loss: 0.08196309953927994\t\tEpoch: 72, Val-loss: 0.08283039927482605\n",
      "Epoch: 74, Loss: 0.08192566782236099\t\tEpoch: 74, Val-loss: 0.08284299820661545\n",
      "Epoch: 76, Loss: 0.08188905566930771\t\tEpoch: 76, Val-loss: 0.08285651355981827\n",
      "Epoch: 78, Loss: 0.08185319602489471\t\tEpoch: 78, Val-loss: 0.08287091553211212\n",
      "Epoch: 80, Loss: 0.08181800693273544\t\tEpoch: 80, Val-loss: 0.08288613706827164\n",
      "Epoch: 82, Loss: 0.08178345113992691\t\tEpoch: 82, Val-loss: 0.08290213346481323\n",
      "Epoch: 84, Loss: 0.08174946159124374\t\tEpoch: 84, Val-loss: 0.08291886001825333\n",
      "Epoch: 86, Loss: 0.08171599358320236\t\tEpoch: 86, Val-loss: 0.08293625712394714\n",
      "Epoch: 88, Loss: 0.08168299496173859\t\tEpoch: 88, Val-loss: 0.0829542949795723\n",
      "Epoch: 90, Loss: 0.08165042102336884\t\tEpoch: 90, Val-loss: 0.0829729437828064\n",
      "Epoch: 92, Loss: 0.08161825686693192\t\tEpoch: 92, Val-loss: 0.08299218863248825\n",
      "Epoch: 94, Loss: 0.08158645033836365\t\tEpoch: 94, Val-loss: 0.08301197737455368\n",
      "Epoch: 96, Loss: 0.08155497908592224\t\tEpoch: 96, Val-loss: 0.08303231000900269\n",
      "Epoch: 98, Loss: 0.08152381330728531\t\tEpoch: 98, Val-loss: 0.08305312693119049\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluation\n",
    "for epoch in range(epochs):\n",
    "    losses = torch.tensor([0])\n",
    "    for i in range(train_len-10):\n",
    "        train_input = train_tensor[:,:,:,i:i+10] #input Rx1\n",
    "        train_target = torch.transpose(train_tensor[:,:,:,i+10:i+11],2,3)\n",
    "        \n",
    "        cnn_extractor.train()\n",
    "        y_pred = cnn_extractor(train_input)\n",
    "        loss = loss_fnc(train_target, y_pred)\n",
    "        losses = torch.hstack((losses, loss))\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    if epoch%2==0:\n",
    "        cnn_extractor.eval()\n",
    "        val_losses = torch.tensor([0])\n",
    "        for i in range(val_len-10):\n",
    "#             cnn_extractor.eval()\n",
    "            val_input = val_tensor[:,:,:,i:i+10]\n",
    "            val_target = torch.transpose(val_tensor[:,:,:,i+10:i+11],2,3)\n",
    "            y_val = cnn_extractor(val_input)\n",
    "            val_loss = loss_fnc(val_target, y_val)\n",
    "            val_losses = torch.dstack((val_losses, val_loss))\n",
    "\n",
    "        val_avg = torch.mean(val_losses)\n",
    "        train_avg = torch.mean(losses)\n",
    "        print(f'Epoch: {epoch}, Loss: {train_avg}\\t\\tEpoch: {epoch}, Val-loss: {val_avg}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0dbb7dea-f327-46f4-8a2f-59d47f18ecd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 1, 30])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cdd71a59-8749-4922-a94d-59f416d86a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_data = test_tensor[:,:,:,0:5] \n",
    "# prediction = cnn_extractor(test_data)\n",
    "# test_target = test_tensor[:,:,:,5:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b54364b5-5fc9-44fe-a484-183fc40116b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_evaluate(data, comment):\n",
    "    test_losses = torch.tensor([0])\n",
    "    for i in range(data.shape[3]-10):\n",
    "        test_data = data[:,:,:,i:i+10]\n",
    "        test_target = torch.transpose(data[:,:,:,i+10:i+11],2,3)\n",
    "        prediction = cnn_extractor(test_data)\n",
    "\n",
    "        test_loss = loss_fnc(test_target, prediction)\n",
    "        test_losses = torch.dstack((test_loss, test_losses))\n",
    "    \n",
    "    test_avg = torch.mean(test_losses)\n",
    "    print(f'Comment: {comment}\\nTest Loss : {test_avg}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b1a0ea1f-1cb9-4a38-bc37-3564762b335e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comment: dawon2\n",
      "Test Loss : 0.08292575180530548\n"
     ]
    }
   ],
   "source": [
    "test_evaluate(test_tensor, \"dawon2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4d4d321d-7fd1-4650-9584-44745674b4ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comment: dawon\n",
      "Test Loss : 0.08292575180530548\n"
     ]
    }
   ],
   "source": [
    "test_evaluate(test_tensor, \"dawon\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d8ab73c8-95bf-415e-867e-0fcd32087af0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comment: Global+local\n",
      "Test Loss : 0.08292575180530548\n"
     ]
    }
   ],
   "source": [
    "test_evaluate(test_tensor, \"Global+local\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5cb294bc-ab3f-4c44-8d4d-816e6c3f3e89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comment: Larger dataset\n",
      "Test Loss : 0.08292575180530548\n"
     ]
    }
   ],
   "source": [
    "test_evaluate(test_tensor, \"Larger dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a4bfef87-c496-49d8-8439-9ec4c8d78946",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comment: Without ReLu\n",
      "Test Loss : 0.08292575180530548\n"
     ]
    }
   ],
   "source": [
    "test_evaluate(test_tensor, \"Without ReLu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b4901d1c-1138-4e33-a3a8-ace430c5c9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Evaluate with test data\n",
    "# test_losses = torch.tensor([0])\n",
    "# for i in range(test_len-5):\n",
    "#     test_data = test_tensor[:,:,:,i:i+5]\n",
    "#     test_target = torch.transpose(test_tensor[:,:,:,i+5:i+6],2,3)\n",
    "#     prediction = cnn_extractor(test_data)\n",
    "    \n",
    "#     test_loss = loss_fnc(test_target, prediction)\n",
    "#     test_losses = torch.dstack((test_loss, test_losses))\n",
    "\n",
    "# test_avg = torch.mean(test_losses)\n",
    "# print(f'Test Loss : {test_avg}')\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
