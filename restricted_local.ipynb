{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56418399-f07b-4edb-beb9-e43df2d555b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variatin of CNN Extractor\n",
    "# Given temporal matrix of w(window size) long, global kernel sweeps the entire matrix while local kernel only passes the last wl time steps of the matrix\n",
    "# This experimenet was conducted based on the assumption that global trends span across longer time than local features which might be obsolete if they are from far past"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2d22e4e5-acc5-43b0-8c76-8b714173fc29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorly as tl\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import statistics\n",
    "import sys\n",
    "import torch.optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "126b25f4-ecbb-4fb0-bafb-3a647adc6264",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"home/seyunkim/Documents/time_series_data/PEMS-SF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0364e942-2ae3-415b-b4dd-605236c23dde",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# data preprocessing 1 batch : (963,144)\n",
    "temp1 = []\n",
    "temp2 = []\n",
    "temp3 = []\n",
    "\n",
    "data1 = []\n",
    "data2 = []\n",
    "data3 = []\n",
    "start = 0\n",
    "indx = 0\n",
    "with open(\"/home/seyunkim/Documents/time_series_data/PEMS-SF/PEMS_train\") as f:\n",
    "    for i, line in enumerate(f):\n",
    "        if i==1:\n",
    "            line = f.readline()\n",
    "            line = line[1:len(line)-1]\n",
    "            indx = line.find(';',indx,-1)\n",
    "            temp1 = line[start:indx]\n",
    "            data1 = np.asarray(temp1.split(' '))\n",
    "            start = indx+1\n",
    "            temp1 = []\n",
    "            while line.find(';',start,-1)!=-1:\n",
    "                indx = line.find(';',start,-1)\n",
    "                temp1 = line[start:indx]\n",
    "                tempnp = np.asarray(temp1.split(' '))\n",
    "                data1 = np.vstack((tempnp, data1))\n",
    "                temp1=[]\n",
    "                start=indx+1\n",
    "            temp1 = line[start:-1]\n",
    "            data1 = np.vstack((data1,np.asarray(temp1.split(' '))))\n",
    "        if i==2:\n",
    "            start = 0\n",
    "            indx = 0\n",
    "            line = f.readline()\n",
    "            line = line[1:len(line)-1]\n",
    "            indx = line.find(';',indx,-1)\n",
    "            temp2 = line[start:indx]\n",
    "            data2 = np.asarray(temp2.split(' '))\n",
    "            start = indx+1\n",
    "            temp2 = []\n",
    "            while line.find(';',start,-1)!=-1:\n",
    "                indx = line.find(';',start,-1)\n",
    "                temp2 = line[start:indx]\n",
    "                tempnp = np.asarray(temp2.split(' '))\n",
    "                data2 = np.vstack((tempnp, data2))\n",
    "                temp2=[]\n",
    "                start=indx+1\n",
    "            temp2 = line[start:-1]\n",
    "            data2 = np.vstack((data2,np.asarray(temp2.split(' '))))\n",
    "        if i==3:\n",
    "            start = 0\n",
    "            indx = 0\n",
    "            line = f.readline()\n",
    "            line = line[1:len(line)-1]\n",
    "            indx = line.find(';',indx,-1)\n",
    "            temp3 = line[start:indx]\n",
    "            data3 = np.asarray(temp3.split(' '))\n",
    "            start = indx+1\n",
    "            temp3 = []\n",
    "            while line.find(';',start,-1)!=-1:\n",
    "                indx = line.find(';',start,-1)\n",
    "                temp3 = line[start:indx]\n",
    "                tempnp = np.asarray(temp3.split(' '))\n",
    "                data3 = np.vstack((tempnp, data3))\n",
    "                temp3=[]\n",
    "                start=indx+1\n",
    "            temp3 = line[start:-1]\n",
    "            data3 = np.vstack((data3,np.asarray(temp3.split(' '))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fed0ba54-d8bb-40e6-94ce-bfb730eef675",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(963, 144)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d0409b57-3a3e-49b2-915a-04f9967f5785",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tensor=torch.FloatTensor(np.ndarray.astype(data1,'float32').reshape(1,1,963,144))\n",
    "val_tensor=torch.FloatTensor(np.ndarray.astype(data2,'float32').reshape(1,1,963,144))\n",
    "test_tensor=torch.FloatTensor(np.ndarray.astype(data3,'float32').reshape(1,1,963,144))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "888e8253-bcdf-470a-837d-f971d4d80990",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Lambda(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "#         self.func = func\n",
    "    \n",
    "#     def forward(self, x):\n",
    "#         return self.func(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f7e01b3-8a92-4efd-b57f-0812bdc1c998",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tl.set_backend('numpy')\n",
    "# tensor_data = torch.FloatTensor(np.random.rand(1,1,30,500))\n",
    "# split = tensor_data.shape[3]//4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23e111e3-3477-4d15-8660-37224670935f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_tensor = tensor_data[:,:,:,0:split*2]\n",
    "# test_tensor = tensor_data[:,:,:,split*2:split*3]\n",
    "# val_tensor = tensor_data[:,:,:,split*3:tensor_data.shape[3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "73e579cd-aac5-4de8-b7cc-4d3b8c865f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_Extractor(nn.Module):\n",
    "    def __init__(self, w, lw, R, gKernel, lKernel):\n",
    "        super().__init__()\n",
    "        #self.local_kernel = local_kernel\n",
    "        #self.global_kernel =  global_kernel\n",
    "        self.w = w\n",
    "        self.R = R\n",
    "        self.gKernel = gKernel\n",
    "        self.lKernel = lKernel\n",
    "        self.conv2d_local = nn.Conv2d(1,1,(self.R,self.lKernel)) # 30x1\n",
    "        self.conv2d_global = nn.Conv2d(1,1,(self.R,self.gKernel)) # 30x5\n",
    "        self.fc = nn.Linear(in_features=w-gKernel+lw-lKernel+2, out_features=self.R) \n",
    "            # Change this number of out_features to forecast longer time\n",
    "            \n",
    "    def forward(self, x):\n",
    "        _local = self.conv2d_local(x[:,:,:,w-lw-1:-1])\n",
    "        _global = self.conv2d_global(x)\n",
    "        x = torch.cat((_local,_global),3)\n",
    "        x = self.fc(x)\n",
    "        x = torch.tanh(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "4fa3d51d-af4e-415f-b660-c47f46a572d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "learning_rate = 1e-3\n",
    "train_len = train_tensor.shape[3]\n",
    "val_len = val_tensor.shape[3]\n",
    "# test_len = test_tensor.shape[3]\n",
    "epochs = 100\n",
    "w = 100 # window size for global kernel\n",
    "gK = 50 # i\n",
    "lw = 50\n",
    "lK = 5\n",
    "# Create Model\n",
    "cnn_extractor = CNN_Extractor(w,lw, 963,gK,lK)\n",
    "loss_fnc = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(cnn_extractor.parameters(), lr=learning_rate, momentum=0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "1870f3b2-884e-4c7b-8062-f6a6575baf3b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 0.008826905861496925\t\tEpoch: 0, Val-loss: 0.007321014069020748\n",
      "Epoch: 2, Loss: 0.008783906698226929\t\tEpoch: 2, Val-loss: 0.007298081647604704\n",
      "Epoch: 4, Loss: 0.008753555826842785\t\tEpoch: 4, Val-loss: 0.007275958079844713\n",
      "Epoch: 6, Loss: 0.00872502289712429\t\tEpoch: 6, Val-loss: 0.0072539858520030975\n",
      "Epoch: 8, Loss: 0.008697469718754292\t\tEpoch: 8, Val-loss: 0.007232161238789558\n",
      "Epoch: 10, Loss: 0.008670530281960964\t\tEpoch: 10, Val-loss: 0.0072104488499462605\n",
      "Epoch: 12, Loss: 0.008644013665616512\t\tEpoch: 12, Val-loss: 0.0071888272650539875\n",
      "Epoch: 14, Loss: 0.008617807179689407\t\tEpoch: 14, Val-loss: 0.0071672843769192696\n",
      "Epoch: 16, Loss: 0.008591845631599426\t\tEpoch: 16, Val-loss: 0.007145813666284084\n",
      "Epoch: 18, Loss: 0.008566087111830711\t\tEpoch: 18, Val-loss: 0.007124410942196846\n",
      "Epoch: 20, Loss: 0.00854050274938345\t\tEpoch: 20, Val-loss: 0.007103077135980129\n",
      "Epoch: 22, Loss: 0.008515072986483574\t\tEpoch: 22, Val-loss: 0.0070818099193274975\n",
      "Epoch: 24, Loss: 0.008489786647260189\t\tEpoch: 24, Val-loss: 0.007060613017529249\n",
      "Epoch: 26, Loss: 0.008464633487164974\t\tEpoch: 26, Val-loss: 0.00703948549926281\n",
      "Epoch: 28, Loss: 0.008439604192972183\t\tEpoch: 28, Val-loss: 0.0070184278301894665\n",
      "Epoch: 30, Loss: 0.008414695039391518\t\tEpoch: 30, Val-loss: 0.006997442804276943\n",
      "Epoch: 32, Loss: 0.00838990043848753\t\tEpoch: 32, Val-loss: 0.006976529024541378\n",
      "Epoch: 34, Loss: 0.008365216664969921\t\tEpoch: 34, Val-loss: 0.0069556874223053455\n",
      "Epoch: 36, Loss: 0.008340642787516117\t\tEpoch: 36, Val-loss: 0.006934918463230133\n",
      "Epoch: 38, Loss: 0.008316174149513245\t\tEpoch: 38, Val-loss: 0.00691422400996089\n",
      "Epoch: 40, Loss: 0.008291808888316154\t\tEpoch: 40, Val-loss: 0.006893603131175041\n",
      "Epoch: 42, Loss: 0.008267546072602272\t\tEpoch: 42, Val-loss: 0.006873055826872587\n",
      "Epoch: 44, Loss: 0.008243381977081299\t\tEpoch: 44, Val-loss: 0.0068525830283761024\n",
      "Epoch: 46, Loss: 0.008219316601753235\t\tEpoch: 46, Val-loss: 0.006832185201346874\n",
      "Epoch: 48, Loss: 0.008195348083972931\t\tEpoch: 48, Val-loss: 0.006811861414462328\n",
      "Epoch: 50, Loss: 0.008171475492417812\t\tEpoch: 50, Val-loss: 0.006791612133383751\n",
      "Epoch: 52, Loss: 0.008147697895765305\t\tEpoch: 52, Val-loss: 0.00677143782377243\n",
      "Epoch: 54, Loss: 0.008124013431370258\t\tEpoch: 54, Val-loss: 0.006751338019967079\n",
      "Epoch: 56, Loss: 0.008100421167910099\t\tEpoch: 56, Val-loss: 0.006731312721967697\n",
      "Epoch: 58, Loss: 0.008076921105384827\t\tEpoch: 58, Val-loss: 0.006711363326758146\n",
      "Epoch: 60, Loss: 0.008053510449826717\t\tEpoch: 60, Val-loss: 0.00669148750603199\n",
      "Epoch: 62, Loss: 0.00803019106388092\t\tEpoch: 62, Val-loss: 0.006671686191111803\n",
      "Epoch: 64, Loss: 0.008006961084902287\t\tEpoch: 64, Val-loss: 0.006651959381997585\n",
      "Epoch: 66, Loss: 0.007983818650245667\t\tEpoch: 66, Val-loss: 0.006632306147366762\n",
      "Epoch: 68, Loss: 0.00796076562255621\t\tEpoch: 68, Val-loss: 0.006612726487219334\n",
      "Epoch: 70, Loss: 0.007937797345221043\t\tEpoch: 70, Val-loss: 0.006593222729861736\n",
      "Epoch: 72, Loss: 0.007914917543530464\t\tEpoch: 72, Val-loss: 0.006573791615664959\n",
      "Epoch: 74, Loss: 0.007892122492194176\t\tEpoch: 74, Val-loss: 0.006554434075951576\n",
      "Epoch: 76, Loss: 0.007869414053857327\t\tEpoch: 76, Val-loss: 0.006535150110721588\n",
      "Epoch: 78, Loss: 0.007846789434552193\t\tEpoch: 78, Val-loss: 0.006515939254313707\n",
      "Epoch: 80, Loss: 0.007824251428246498\t\tEpoch: 80, Val-loss: 0.006496801506727934\n",
      "Epoch: 82, Loss: 0.007801796309649944\t\tEpoch: 82, Val-loss: 0.006477737333625555\n",
      "Epoch: 84, Loss: 0.007779424078762531\t\tEpoch: 84, Val-loss: 0.006458745338022709\n",
      "Epoch: 86, Loss: 0.007757135201245546\t\tEpoch: 86, Val-loss: 0.006439826916903257\n",
      "Epoch: 88, Loss: 0.0077349296770989895\t\tEpoch: 88, Val-loss: 0.006420979276299477\n",
      "Epoch: 90, Loss: 0.007712805178016424\t\tEpoch: 90, Val-loss: 0.0064022052101790905\n",
      "Epoch: 92, Loss: 0.007690762635320425\t\tEpoch: 92, Val-loss: 0.0063835023902356625\n",
      "Epoch: 94, Loss: 0.007668802514672279\t\tEpoch: 94, Val-loss: 0.006364872213453054\n",
      "Epoch: 96, Loss: 0.007646922953426838\t\tEpoch: 96, Val-loss: 0.00634631235152483\n",
      "Epoch: 98, Loss: 0.007625123020261526\t\tEpoch: 98, Val-loss: 0.006327824667096138\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluation\n",
    "for epoch in range(epochs):\n",
    "    losses = torch.FloatTensor([0])\n",
    "    for i in range(train_len-w):\n",
    "        train_input = train_tensor[:,:,:,i:i+w] #input Rx1\n",
    "        train_target = torch.transpose(train_tensor[:,:,:,i+w:i+w+1],2,3)\n",
    "        \n",
    "        cnn_extractor.train()\n",
    "        y_pred = cnn_extractor(train_input)\n",
    "        loss = loss_fnc(train_target, y_pred)\n",
    "        losses = torch.hstack((losses, loss))\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    if epoch%2==0:\n",
    "        cnn_extractor.eval()\n",
    "        val_losses = torch.FloatTensor([0])\n",
    "        for i in range(val_len-w):\n",
    "#             cnn_extractor.eval()\n",
    "            val_input = val_tensor[:,:,:,i:i+w]\n",
    "            val_target = torch.transpose(val_tensor[:,:,:,i+w:i+w+1],2,3)\n",
    "            y_val = cnn_extractor(val_input)\n",
    "            val_loss = loss_fnc(val_target, y_val)\n",
    "            val_losses = torch.dstack((val_losses, val_loss))\n",
    "        val_avg = torch.mean(val_losses)\n",
    "        train_avg = torch.mean(losses)\n",
    "        print(f'Epoch: {epoch}, Loss: {train_avg}\\t\\tEpoch: {epoch}, Val-loss: {val_avg}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b54364b5-5fc9-44fe-a484-183fc40116b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_evaluate(data, w, comment):\n",
    "    test_losses = torch.tensor([0])\n",
    "    for i in range(data.shape[3]-w):\n",
    "        test_data = data[:,:,:,i:i+w]\n",
    "        test_target = torch.transpose(data[:,:,:,i+w:i+w+1],2,3)\n",
    "        prediction = cnn_extractor(test_data)\n",
    "\n",
    "        test_loss = loss_fnc(test_target, prediction)\n",
    "        test_losses = torch.dstack((test_loss, test_losses))\n",
    "    \n",
    "    test_avg = torch.mean(test_losses)\n",
    "    print(f'Comment: {comment}\\nTest Loss : {test_avg}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "aabca9e2-771e-41d5-8168-d36d331ce8c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comment: w=100, w = 100, gK = 50, lw = 50,lK = 5\n",
      "Test Loss : 0.007040831726044416\n"
     ]
    }
   ],
   "source": [
    "test_evaluate(test_tensor, w, \"w=100, w = 100, gK = 50, lw = 50,lK = 5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7580c1-d618-40b7-b1ee-20e6634ed140",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_evaluate(test_tensor, w, \"w=100, gk=50\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a62b6ea4-eff3-4f6c-836d-2f83c74983e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comment: w=100\n",
      "Test Loss : 0.005983165465295315\n"
     ]
    }
   ],
   "source": [
    "test_evaluate(test_tensor, w, \"w=100\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f8dcdddc-0d2f-4526-bdd9-bc59cb490264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comment: real data\n",
      "Test Loss : 0.00761840958148241\n"
     ]
    }
   ],
   "source": [
    "test_evaluate(test_tensor, w, \"real data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e138e81a-a2d0-4687-85f0-3921d7f30d87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comment: fixed eval\n",
      "Test Loss : 0.08689478039741516\n"
     ]
    }
   ],
   "source": [
    "test_evaluate(test_tensor, \"fixed eval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d4d321d-7fd1-4650-9584-44745674b4ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comment: dawon\n",
      "Test Loss : 0.08689478039741516\n"
     ]
    }
   ],
   "source": [
    "test_evaluate(test_tensor, \"dawon\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8ab73c8-95bf-415e-867e-0fcd32087af0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comment: Global+local\n",
      "Test Loss : 0.08689478039741516\n"
     ]
    }
   ],
   "source": [
    "test_evaluate(test_tensor, \"Global+local\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5cb294bc-ab3f-4c44-8d4d-816e6c3f3e89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comment: Larger dataset\n",
      "Test Loss : 0.08689478039741516\n"
     ]
    }
   ],
   "source": [
    "test_evaluate(test_tensor, \"Larger dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a4bfef87-c496-49d8-8439-9ec4c8d78946",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comment: Without ReLu\n",
      "Test Loss : 0.08689478039741516\n"
     ]
    }
   ],
   "source": [
    "test_evaluate(test_tensor, \"Without ReLu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b4901d1c-1138-4e33-a3a8-ace430c5c9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Evaluate with test data\n",
    "# test_losses = torch.tensor([0])\n",
    "# for i in range(test_len-5):\n",
    "#     test_data = test_tensor[:,:,:,i:i+5]\n",
    "#     test_target = torch.transpose(test_tensor[:,:,:,i+5:i+6],2,3)\n",
    "#     prediction = cnn_extractor(test_data)\n",
    "    \n",
    "#     test_loss = loss_fnc(test_target, prediction)\n",
    "#     test_losses = torch.dstack((test_loss, test_losses))\n",
    "\n",
    "# test_avg = torch.mean(test_losses)\n",
    "# print(f'Test Loss : {test_avg}')\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
