{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d22e4e5-acc5-43b0-8c76-8b714173fc29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorly as tl\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import statistics\n",
    "import torch.optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "888e8253-bcdf-470a-837d-f971d4d80990",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lambda(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.func = func\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.func(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f7e01b3-8a92-4efd-b57f-0812bdc1c998",
   "metadata": {},
   "outputs": [],
   "source": [
    "tl.set_backend('numpy')\n",
    "tensor_data = torch.FloatTensor(np.random.rand(1,1,30,500))\n",
    "split = tensor_data.shape[3]//4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23e111e3-3477-4d15-8660-37224670935f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tensor = tensor_data[:,:,:,0:split*2]\n",
    "test_tensor = tensor_data[:,:,:,split*2:split*3]\n",
    "val_tensor = tensor_data[:,:,:,split*3:tensor_data.shape[3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73e579cd-aac5-4de8-b7cc-4d3b8c865f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_Extractor(nn.Module):\n",
    "    def __init__(self, w, R, gKernel, lKernel):\n",
    "        super().__init__()\n",
    "        #self.local_kernel = local_kernel\n",
    "        #self.global_kernel =  global_kernel\n",
    "        self.w = w\n",
    "        self.R = R\n",
    "        self.gKernel = gKernel\n",
    "        self.lKernel = lKernel\n",
    "        self.conv2d_local = nn.Conv2d(1,1,(self.R,self.lKernel)) # 30x1\n",
    "        self.conv2d_global = nn.Conv2d(1,1,(self.R,self.gKernel)) # 30x5\n",
    "        self.fc = nn.Linear(in_features=2*self.w-lKernel-gKernel+2, out_features=self.R) \n",
    "            # Change this number of out_features to forecast longer time\n",
    "            \n",
    "    def forward(self, x):\n",
    "        _local = self.conv2d_local(x)\n",
    "        _global = self.conv2d_global(x)\n",
    "        x = torch.cat((_local,_global),3)\n",
    "        x = self.fc(x)\n",
    "        x = torch.tanh(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4fa3d51d-af4e-415f-b660-c47f46a572d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "learning_rate = 1e-3\n",
    "train_len = train_tensor.shape[3]\n",
    "val_len = val_tensor.shape[3]\n",
    "test_len = test_tensor.shape[3]\n",
    "epochs = 100\n",
    "# Create Model\n",
    "cnn_extractor = CNN_Extractor(10,30,5,1)\n",
    "loss_fnc = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(cnn_extractor.parameters(), lr=learning_rate, momentum=0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1870f3b2-884e-4c7b-8062-f6a6575baf3b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/seyunkim/anaconda3/envs/syenv/lib/python3.6/site-packages/torch/autograd/__init__.py:147: UserWarning: CUDA initialization: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:109.)\n",
      "  allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 0.28549689054489136\t\tEpoch: 0, Val-loss: 0.13513292372226715\n",
      "Epoch: 2, Loss: 0.08809417486190796\t\tEpoch: 2, Val-loss: 0.08547346293926239\n",
      "Epoch: 4, Loss: 0.08623126149177551\t\tEpoch: 4, Val-loss: 0.08493103086948395\n",
      "Epoch: 6, Loss: 0.08554567396640778\t\tEpoch: 6, Val-loss: 0.08462851494550705\n",
      "Epoch: 8, Loss: 0.08498939871788025\t\tEpoch: 8, Val-loss: 0.0843866765499115\n",
      "Epoch: 10, Loss: 0.08453048020601273\t\tEpoch: 10, Val-loss: 0.08419355750083923\n",
      "Epoch: 12, Loss: 0.08414854854345322\t\tEpoch: 12, Val-loss: 0.0840393602848053\n",
      "Epoch: 14, Loss: 0.08382795751094818\t\tEpoch: 14, Val-loss: 0.08391641080379486\n",
      "Epoch: 16, Loss: 0.08355659246444702\t\tEpoch: 16, Val-loss: 0.0838187038898468\n",
      "Epoch: 18, Loss: 0.08332496136426926\t\tEpoch: 18, Val-loss: 0.08374152332544327\n",
      "Epoch: 20, Loss: 0.08312563598155975\t\tEpoch: 20, Val-loss: 0.08368109911680222\n",
      "Epoch: 22, Loss: 0.08295270055532455\t\tEpoch: 22, Val-loss: 0.08363442867994308\n",
      "Epoch: 24, Loss: 0.0828014463186264\t\tEpoch: 24, Val-loss: 0.08359910547733307\n",
      "Epoch: 26, Loss: 0.08266814798116684\t\tEpoch: 26, Val-loss: 0.08357317745685577\n",
      "Epoch: 28, Loss: 0.08254973590373993\t\tEpoch: 28, Val-loss: 0.08355507999658585\n",
      "Epoch: 30, Loss: 0.08244378864765167\t\tEpoch: 30, Val-loss: 0.08354351669549942\n",
      "Epoch: 32, Loss: 0.0823483094573021\t\tEpoch: 32, Val-loss: 0.08353743702173233\n",
      "Epoch: 34, Loss: 0.08226167410612106\t\tEpoch: 34, Val-loss: 0.08353599905967712\n",
      "Epoch: 36, Loss: 0.08218253403902054\t\tEpoch: 36, Val-loss: 0.08353851735591888\n",
      "Epoch: 38, Loss: 0.08210979402065277\t\tEpoch: 38, Val-loss: 0.08354436606168747\n",
      "Epoch: 40, Loss: 0.08204252272844315\t\tEpoch: 40, Val-loss: 0.08355309814214706\n",
      "Epoch: 42, Loss: 0.08197998255491257\t\tEpoch: 42, Val-loss: 0.08356428146362305\n",
      "Epoch: 44, Loss: 0.0819215252995491\t\tEpoch: 44, Val-loss: 0.08357761055231094\n",
      "Epoch: 46, Loss: 0.08186662197113037\t\tEpoch: 46, Val-loss: 0.08359279483556747\n",
      "Epoch: 48, Loss: 0.08181481808423996\t\tEpoch: 48, Val-loss: 0.08360961079597473\n",
      "Epoch: 50, Loss: 0.08176574110984802\t\tEpoch: 50, Val-loss: 0.0836278647184372\n",
      "Epoch: 52, Loss: 0.0817190483212471\t\tEpoch: 52, Val-loss: 0.08364737778902054\n",
      "Epoch: 54, Loss: 0.0816744714975357\t\tEpoch: 54, Val-loss: 0.08366801589727402\n",
      "Epoch: 56, Loss: 0.08163177967071533\t\tEpoch: 56, Val-loss: 0.08368967473506927\n",
      "Epoch: 58, Loss: 0.08159076422452927\t\tEpoch: 58, Val-loss: 0.08371223509311676\n",
      "Epoch: 60, Loss: 0.08155124634504318\t\tEpoch: 60, Val-loss: 0.08373561501502991\n",
      "Epoch: 62, Loss: 0.08151306211948395\t\tEpoch: 62, Val-loss: 0.08375975489616394\n",
      "Epoch: 64, Loss: 0.08147609233856201\t\tEpoch: 64, Val-loss: 0.0837845727801323\n",
      "Epoch: 66, Loss: 0.08144021034240723\t\tEpoch: 66, Val-loss: 0.08381003141403198\n",
      "Epoch: 68, Loss: 0.08140532672405243\t\tEpoch: 68, Val-loss: 0.08383606374263763\n",
      "Epoch: 70, Loss: 0.08137132972478867\t\tEpoch: 70, Val-loss: 0.08386265486478806\n",
      "Epoch: 72, Loss: 0.08133814483880997\t\tEpoch: 72, Val-loss: 0.08388976752758026\n",
      "Epoch: 74, Loss: 0.08130572736263275\t\tEpoch: 74, Val-loss: 0.08391731232404709\n",
      "Epoch: 76, Loss: 0.08127398043870926\t\tEpoch: 76, Val-loss: 0.08394533395767212\n",
      "Epoch: 78, Loss: 0.08124285191297531\t\tEpoch: 78, Val-loss: 0.08397378027439117\n",
      "Epoch: 80, Loss: 0.08121231198310852\t\tEpoch: 80, Val-loss: 0.08400262892246246\n",
      "Epoch: 82, Loss: 0.08118229359388351\t\tEpoch: 82, Val-loss: 0.0840318500995636\n",
      "Epoch: 84, Loss: 0.08115275204181671\t\tEpoch: 84, Val-loss: 0.08406145125627518\n",
      "Epoch: 86, Loss: 0.08112369477748871\t\tEpoch: 86, Val-loss: 0.08409140259027481\n",
      "Epoch: 88, Loss: 0.08109503239393234\t\tEpoch: 88, Val-loss: 0.08412168174982071\n",
      "Epoch: 90, Loss: 0.08106676489114761\t\tEpoch: 90, Val-loss: 0.08415227383375168\n",
      "Epoch: 92, Loss: 0.08103886246681213\t\tEpoch: 92, Val-loss: 0.08418318629264832\n",
      "Epoch: 94, Loss: 0.08101128786802292\t\tEpoch: 94, Val-loss: 0.08421438187360764\n",
      "Epoch: 96, Loss: 0.08098402619361877\t\tEpoch: 96, Val-loss: 0.08424587547779083\n",
      "Epoch: 98, Loss: 0.08095705509185791\t\tEpoch: 98, Val-loss: 0.08427765220403671\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluation\n",
    "for epoch in range(epochs):\n",
    "    losses = torch.tensor([0])\n",
    "    for i in range(train_len-10):\n",
    "        train_input = train_tensor[:,:,:,i:i+10] #input Rx1\n",
    "        train_target = torch.transpose(train_tensor[:,:,:,i+10:i+11],2,3)\n",
    "        \n",
    "        cnn_extractor.train()\n",
    "        y_pred = cnn_extractor(train_input)\n",
    "        loss = loss_fnc(train_target, y_pred)\n",
    "        losses = torch.hstack((losses, loss))\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    if epoch%2==0:\n",
    "        cnn_extractor.eval()\n",
    "        val_losses = torch.tensor([0])\n",
    "        for i in range(val_len-10):\n",
    "#             cnn_extractor.eval()\n",
    "            val_input = val_tensor[:,:,:,i:i+10]\n",
    "            val_target = torch.transpose(val_tensor[:,:,:,i+10:i+11],2,3)\n",
    "            y_val = cnn_extractor(val_input)\n",
    "            val_loss = loss_fnc(val_target, y_val)\n",
    "            val_losses = torch.dstack((val_losses, val_loss))\n",
    "\n",
    "        val_avg = torch.mean(val_losses)\n",
    "        train_avg = torch.mean(losses)\n",
    "        print(f'Epoch: {epoch}, Loss: {train_avg}\\t\\tEpoch: {epoch}, Val-loss: {val_avg}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b54364b5-5fc9-44fe-a484-183fc40116b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_evaluate(data, comment):\n",
    "    test_losses = torch.tensor([0])\n",
    "    for i in range(data.shape[3]-10):\n",
    "        test_data = data[:,:,:,i:i+10]\n",
    "        test_target = torch.transpose(data[:,:,:,i+10:i+11],2,3)\n",
    "        prediction = cnn_extractor(test_data)\n",
    "\n",
    "        test_loss = loss_fnc(test_target, prediction)\n",
    "        test_losses = torch.dstack((test_loss, test_losses))\n",
    "    \n",
    "    test_avg = torch.mean(test_losses)\n",
    "    print(f'Comment: {comment}\\nTest Loss : {test_avg}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e138e81a-a2d0-4687-85f0-3921d7f30d87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comment: fixed eval\n",
      "Test Loss : 0.08689478039741516\n"
     ]
    }
   ],
   "source": [
    "test_evaluate(test_tensor, \"fixed eval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d4d321d-7fd1-4650-9584-44745674b4ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comment: dawon\n",
      "Test Loss : 0.08689478039741516\n"
     ]
    }
   ],
   "source": [
    "test_evaluate(test_tensor, \"dawon\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8ab73c8-95bf-415e-867e-0fcd32087af0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comment: Global+local\n",
      "Test Loss : 0.08689478039741516\n"
     ]
    }
   ],
   "source": [
    "test_evaluate(test_tensor, \"Global+local\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5cb294bc-ab3f-4c44-8d4d-816e6c3f3e89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comment: Larger dataset\n",
      "Test Loss : 0.08689478039741516\n"
     ]
    }
   ],
   "source": [
    "test_evaluate(test_tensor, \"Larger dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a4bfef87-c496-49d8-8439-9ec4c8d78946",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comment: Without ReLu\n",
      "Test Loss : 0.08689478039741516\n"
     ]
    }
   ],
   "source": [
    "test_evaluate(test_tensor, \"Without ReLu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b4901d1c-1138-4e33-a3a8-ace430c5c9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Evaluate with test data\n",
    "# test_losses = torch.tensor([0])\n",
    "# for i in range(test_len-5):\n",
    "#     test_data = test_tensor[:,:,:,i:i+5]\n",
    "#     test_target = torch.transpose(test_tensor[:,:,:,i+5:i+6],2,3)\n",
    "#     prediction = cnn_extractor(test_data)\n",
    "    \n",
    "#     test_loss = loss_fnc(test_target, prediction)\n",
    "#     test_losses = torch.dstack((test_loss, test_losses))\n",
    "\n",
    "# test_avg = torch.mean(test_losses)\n",
    "# print(f'Test Loss : {test_avg}')\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
