{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d22e4e5-acc5-43b0-8c76-8b714173fc29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorly as tl\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import statistics\n",
    "import torch.optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0214636f-5211-4af3-9347-e87c0b38297c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data preprocessing 1 batch : (963,144)\n",
    "temp1 = []\n",
    "temp2 = []\n",
    "temp3 = []\n",
    "\n",
    "data1 = []\n",
    "data2 = []\n",
    "data3 = []\n",
    "start = 0\n",
    "indx = 0\n",
    "with open(\"/home/seyunkim/Documents/time_series_data/PEMS-SF/PEMS_train\") as f:\n",
    "    for i, line in enumerate(f):\n",
    "        if i==1:\n",
    "            line = f.readline()\n",
    "            line = line[1:len(line)-1]\n",
    "            indx = line.find(';',indx,-1)\n",
    "            temp1 = line[start:indx]\n",
    "            data1 = np.asarray(temp1.split(' '))\n",
    "            start = indx+1\n",
    "            temp1 = []\n",
    "            while line.find(';',start,-1)!=-1:\n",
    "                indx = line.find(';',start,-1)\n",
    "                temp1 = line[start:indx]\n",
    "                tempnp = np.asarray(temp1.split(' '))\n",
    "                data1 = np.vstack((tempnp, data1))\n",
    "                temp1=[]\n",
    "                start=indx+1\n",
    "            temp1 = line[start:-1]\n",
    "            data1 = np.vstack((data1,np.asarray(temp1.split(' '))))\n",
    "        if i==2:\n",
    "            start = 0\n",
    "            indx = 0\n",
    "            line = f.readline()\n",
    "            line = line[1:len(line)-1]\n",
    "            indx = line.find(';',indx,-1)\n",
    "            temp2 = line[start:indx]\n",
    "            data2 = np.asarray(temp2.split(' '))\n",
    "            start = indx+1\n",
    "            temp2 = []\n",
    "            while line.find(';',start,-1)!=-1:\n",
    "                indx = line.find(';',start,-1)\n",
    "                temp2 = line[start:indx]\n",
    "                tempnp = np.asarray(temp2.split(' '))\n",
    "                data2 = np.vstack((tempnp, data2))\n",
    "                temp2=[]\n",
    "                start=indx+1\n",
    "            temp2 = line[start:-1]\n",
    "            data2 = np.vstack((data2,np.asarray(temp2.split(' '))))\n",
    "        if i==3:\n",
    "            start = 0\n",
    "            indx = 0\n",
    "            line = f.readline()\n",
    "            line = line[1:len(line)-1]\n",
    "            indx = line.find(';',indx,-1)\n",
    "            temp3 = line[start:indx]\n",
    "            data3 = np.asarray(temp3.split(' '))\n",
    "            start = indx+1\n",
    "            temp3 = []\n",
    "            while line.find(';',start,-1)!=-1:\n",
    "                indx = line.find(';',start,-1)\n",
    "                temp3 = line[start:indx]\n",
    "                tempnp = np.asarray(temp3.split(' '))\n",
    "                data3 = np.vstack((tempnp, data3))\n",
    "                temp3=[]\n",
    "                start=indx+1\n",
    "            temp3 = line[start:-1]\n",
    "            data3 = np.vstack((data3,np.asarray(temp3.split(' '))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ab4424fa-c17e-41d0-a167-f21f4a140a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tensor=torch.FloatTensor(np.ndarray.astype(data1,'float32').reshape(1,1,963,144))\n",
    "val_tensor=torch.FloatTensor(np.ndarray.astype(data2,'float32').reshape(1,1,963,144))\n",
    "test_tensor=torch.FloatTensor(np.ndarray.astype(data3,'float32').reshape(1,1,963,144))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "888e8253-bcdf-470a-837d-f971d4d80990",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Lambda(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "#         self.func = func\n",
    "    \n",
    "#     def forward(self, x):\n",
    "#         return self.func(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f7e01b3-8a92-4efd-b57f-0812bdc1c998",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tl.set_backend('numpy')\n",
    "# tensor_data = torch.FloatTensor(np.random.rand(1,1,30,500))\n",
    "# split = tensor_data.shape[3]//4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23e111e3-3477-4d15-8660-37224670935f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_tensor = tensor_data[:,:,:,0:split*2]\n",
    "# test_tensor = tensor_data[:,:,:,split*2:split*3]\n",
    "# val_tensor = tensor_data[:,:,:,split*3:tensor_data.shape[3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "73e579cd-aac5-4de8-b7cc-4d3b8c865f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_Extractor(nn.Module):\n",
    "    def __init__(self, w, R):\n",
    "        super().__init__()\n",
    "        #self.local_kernel = local_kernel\n",
    "        #self.global_kernel =  global_kernel\n",
    "#         self.w = w\n",
    "        self.R = R\n",
    "        self.w = w\n",
    "        self.conv2d = nn.Conv2d(1,1,(self.R,1))\n",
    "        self.fc = nn.Linear(in_features=self.w, out_features=self.R) # Change this number of out_features to forecast longer time\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv2d(x)\n",
    "        x = self.fc(x)\n",
    "        x = torch.tanh(x)\n",
    "#         x = F.relu(x)\n",
    "#         x = nn.Conv1d(in_channels=1, out_channels=1, kernel_size=(self.R,2))(x)\n",
    "#         x = nn.Linear(in_features=np.prod(x.shape), out_features=(2*self.R))(x)\n",
    "#         x = F.relU(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4fa3d51d-af4e-415f-b660-c47f46a572d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "learning_rate = 1e-3\n",
    "train_len = train_tensor.shape[3]\n",
    "val_len = val_tensor.shape[3]\n",
    "test_len = test_tensor.shape[3]\n",
    "epochs = 100\n",
    "w = 100\n",
    "# Create Model\n",
    "cnn_extractor = CNN_Extractor(w,963)\n",
    "loss_fnc = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(cnn_extractor.parameters(), lr=learning_rate, momentum=0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1870f3b2-884e-4c7b-8062-f6a6575baf3b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 0.008665638975799084\t\tEpoch: 0, Val-loss: 0.006832281593233347\n",
      "Epoch: 2, Loss: 0.00854423362761736\t\tEpoch: 2, Val-loss: 0.006807421334087849\n",
      "Epoch: 4, Loss: 0.00850010011345148\t\tEpoch: 4, Val-loss: 0.006803241092711687\n",
      "Epoch: 6, Loss: 0.008461720310151577\t\tEpoch: 6, Val-loss: 0.006797481328248978\n",
      "Epoch: 8, Loss: 0.008427277207374573\t\tEpoch: 8, Val-loss: 0.006790291517972946\n",
      "Epoch: 10, Loss: 0.008395512588322163\t\tEpoch: 10, Val-loss: 0.0067817470990121365\n",
      "Epoch: 12, Loss: 0.008365599438548088\t\tEpoch: 12, Val-loss: 0.006771961692720652\n",
      "Epoch: 14, Loss: 0.008336999453604221\t\tEpoch: 14, Val-loss: 0.006761061958968639\n",
      "Epoch: 16, Loss: 0.008309351280331612\t\tEpoch: 16, Val-loss: 0.006749172229319811\n",
      "Epoch: 18, Loss: 0.008282415568828583\t\tEpoch: 18, Val-loss: 0.006736416835337877\n",
      "Epoch: 20, Loss: 0.008256029337644577\t\tEpoch: 20, Val-loss: 0.006722903810441494\n",
      "Epoch: 22, Loss: 0.008230081759393215\t\tEpoch: 22, Val-loss: 0.006708735134452581\n",
      "Epoch: 24, Loss: 0.00820449274033308\t\tEpoch: 24, Val-loss: 0.006693999748677015\n",
      "Epoch: 26, Loss: 0.00817920919507742\t\tEpoch: 26, Val-loss: 0.006678777746856213\n",
      "Epoch: 28, Loss: 0.008154189214110374\t\tEpoch: 28, Val-loss: 0.0066631389781832695\n",
      "Epoch: 30, Loss: 0.008129402995109558\t\tEpoch: 30, Val-loss: 0.006647141184657812\n",
      "Epoch: 32, Loss: 0.008104827255010605\t\tEpoch: 32, Val-loss: 0.006630837917327881\n",
      "Epoch: 34, Loss: 0.008080444298684597\t\tEpoch: 34, Val-loss: 0.006614274345338345\n",
      "Epoch: 36, Loss: 0.008056242018938065\t\tEpoch: 36, Val-loss: 0.006597490981221199\n",
      "Epoch: 38, Loss: 0.008032203651964664\t\tEpoch: 38, Val-loss: 0.006580522283911705\n",
      "Epoch: 40, Loss: 0.008008323609828949\t\tEpoch: 40, Val-loss: 0.006563397124409676\n",
      "Epoch: 42, Loss: 0.007984592579305172\t\tEpoch: 42, Val-loss: 0.006546142511069775\n",
      "Epoch: 44, Loss: 0.007961003109812737\t\tEpoch: 44, Val-loss: 0.006528780795633793\n",
      "Epoch: 46, Loss: 0.007937547750771046\t\tEpoch: 46, Val-loss: 0.006511332001537085\n",
      "Epoch: 48, Loss: 0.007914223708212376\t\tEpoch: 48, Val-loss: 0.006493812892585993\n",
      "Epoch: 50, Loss: 0.007891024462878704\t\tEpoch: 50, Val-loss: 0.006476240232586861\n",
      "Epoch: 52, Loss: 0.007867945358157158\t\tEpoch: 52, Val-loss: 0.006458626128733158\n",
      "Epoch: 54, Loss: 0.007844985462725163\t\tEpoch: 54, Val-loss: 0.006440984550863504\n",
      "Epoch: 56, Loss: 0.007822138257324696\t\tEpoch: 56, Val-loss: 0.0064233229495584965\n",
      "Epoch: 58, Loss: 0.007799400947988033\t\tEpoch: 58, Val-loss: 0.006405652035027742\n",
      "Epoch: 60, Loss: 0.007776773534715176\t\tEpoch: 60, Val-loss: 0.006387980654835701\n",
      "Epoch: 62, Loss: 0.007754249032586813\t\tEpoch: 62, Val-loss: 0.00637031439691782\n",
      "Epoch: 64, Loss: 0.007731829769909382\t\tEpoch: 64, Val-loss: 0.006352661177515984\n",
      "Epoch: 66, Loss: 0.007709510624408722\t\tEpoch: 66, Val-loss: 0.006335026118904352\n",
      "Epoch: 68, Loss: 0.007687291130423546\t\tEpoch: 68, Val-loss: 0.006317414343357086\n",
      "Epoch: 70, Loss: 0.007665167097002268\t\tEpoch: 70, Val-loss: 0.006299829576164484\n",
      "Epoch: 72, Loss: 0.00764313992112875\t\tEpoch: 72, Val-loss: 0.006282276473939419\n",
      "Epoch: 74, Loss: 0.007621206343173981\t\tEpoch: 74, Val-loss: 0.006264758761972189\n",
      "Epoch: 76, Loss: 0.0075993649661540985\t\tEpoch: 76, Val-loss: 0.006247279234230518\n",
      "Epoch: 78, Loss: 0.007577614858746529\t\tEpoch: 78, Val-loss: 0.006229841616004705\n",
      "Epoch: 80, Loss: 0.0075559550896286964\t\tEpoch: 80, Val-loss: 0.0062124477699398994\n",
      "Epoch: 82, Loss: 0.007534383330494165\t\tEpoch: 82, Val-loss: 0.006195098627358675\n",
      "Epoch: 84, Loss: 0.007512898650020361\t\tEpoch: 84, Val-loss: 0.00617779977619648\n",
      "Epoch: 86, Loss: 0.007491502445191145\t\tEpoch: 86, Val-loss: 0.006160549353808165\n",
      "Epoch: 88, Loss: 0.007470190525054932\t\tEpoch: 88, Val-loss: 0.0061433506198227406\n",
      "Epoch: 90, Loss: 0.007448963355273008\t\tEpoch: 90, Val-loss: 0.006126203574240208\n",
      "Epoch: 92, Loss: 0.007427820935845375\t\tEpoch: 92, Val-loss: 0.006109111942350864\n",
      "Epoch: 94, Loss: 0.00740676186978817\t\tEpoch: 94, Val-loss: 0.006092074792832136\n",
      "Epoch: 96, Loss: 0.007385783828794956\t\tEpoch: 96, Val-loss: 0.006075093522667885\n",
      "Epoch: 98, Loss: 0.007364889141172171\t\tEpoch: 98, Val-loss: 0.006058169528841972\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluation\n",
    "for epoch in range(epochs):\n",
    "    losses = torch.tensor([0])\n",
    "    for i in range(train_len-w):\n",
    "        train_input = train_tensor[:,:,:,i:i+w] #input Rx1\n",
    "        train_target = torch.transpose(train_tensor[:,:,:,i+w:i+w+1],2,3)\n",
    "        \n",
    "        cnn_extractor.train()\n",
    "        y_pred = cnn_extractor(train_input)\n",
    "        loss = loss_fnc(train_target, y_pred)\n",
    "        losses = torch.hstack((losses, loss))\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "#         if i%20==0:\n",
    "#             print(f'i: {i}, \\tWeight: {cnn_extractor.conv2d.weight.grad}')\n",
    "    if epoch%2==0:\n",
    "        cnn_extractor.eval()\n",
    "        val_losses = torch.tensor([0])\n",
    "        for i in range(val_len-w):\n",
    "            val_input = val_tensor[:,:,:,i:i+w]\n",
    "            val_target = torch.transpose(val_tensor[:,:,:,i+w:i+w+1],2,3)\n",
    "            y_val = cnn_extractor(val_input)\n",
    "            val_loss = loss_fnc(val_target, y_val)\n",
    "            val_losses = torch.dstack((val_losses, val_loss))\n",
    "\n",
    "        val_avg = torch.mean(val_losses)\n",
    "        train_avg = torch.mean(losses)\n",
    "        print(f'Epoch: {epoch}, Loss: {train_avg}\\t\\tEpoch: {epoch}, Val-loss: {val_avg}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cdd71a59-8749-4922-a94d-59f416d86a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_data = test_tensor[:,:,:,0:5] \n",
    "# prediction = cnn_extractor(test_data)\n",
    "# test_target = test_tensor[:,:,:,5:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b54364b5-5fc9-44fe-a484-183fc40116b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_evaluate(data, window, comment):\n",
    "    test_losses = torch.tensor([0])\n",
    "    for i in range(data.shape[3]-window):\n",
    "        test_data = data[:,:,:,i:i+window]\n",
    "        test_target = torch.transpose(data[:,:,:,i+window:i+window+1],2,3)\n",
    "        prediction = cnn_extractor(test_data)\n",
    "\n",
    "        test_loss = loss_fnc(test_target, prediction)\n",
    "        test_losses = torch.dstack((test_loss, test_losses))\n",
    "    \n",
    "    test_avg = torch.mean(test_losses)\n",
    "    print(f'Comment: {comment}\\nTest Loss : {test_avg}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c70fc0a3-72b1-4ff3-a859-9fb16c30cb38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comment: w=100\n",
      "Test Loss : 0.006913019344210625\n"
     ]
    }
   ],
   "source": [
    "test_evaluate(test_tensor, w, \"w=100\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "96090dca-8fa6-4afc-ac05-a55e294c8e53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comment: real data\n",
      "Test Loss : 0.008898423984646797\n"
     ]
    }
   ],
   "source": [
    "test_evaluate(test_tensor, w, \"real data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5911ba40-ba3e-4575-be80-67ec16b935f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comment: fixed eval\n",
      "Test Loss : 0.08254538476467133\n"
     ]
    }
   ],
   "source": [
    "test_evaluate(test_tensor, \"fixed eval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7ed7910-97a3-4e15-8c33-e79397f85afb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comment: dawon input\n",
      "Test Loss : 0.08254538476467133\n"
     ]
    }
   ],
   "source": [
    "test_evaluate(test_tensor, \"dawon input\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "94c31d56-9025-45f2-aa2b-0aa328881577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comment: larger window, no global\n",
      "Test Loss : 0.08254538476467133\n"
     ]
    }
   ],
   "source": [
    "test_evaluate(test_tensor, \"larger window, no global\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9d98ab08-c1e9-459c-b8ed-87d2615e1f85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comment: Larger dataset\n",
      "Test Loss : 0.08254538476467133\n"
     ]
    }
   ],
   "source": [
    "test_evaluate(test_tensor, \"Larger dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a4bfef87-c496-49d8-8439-9ec4c8d78946",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comment: Without ReLu\n",
      "Test Loss : 0.08254538476467133\n"
     ]
    }
   ],
   "source": [
    "test_evaluate(test_tensor, \"Without ReLu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b4901d1c-1138-4e33-a3a8-ace430c5c9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Evaluate with test data\n",
    "# test_losses = torch.tensor([0])\n",
    "# for i in range(test_len-5):\n",
    "#     test_data = test_tensor[:,:,:,i:i+5]\n",
    "#     test_target = torch.transpose(test_tensor[:,:,:,i+5:i+6],2,3)\n",
    "#     prediction = cnn_extractor(test_data)\n",
    "    \n",
    "#     test_loss = loss_fnc(test_target, prediction)\n",
    "#     test_losses = torch.dstack((test_loss, test_losses))\n",
    "\n",
    "# test_avg = torch.mean(test_losses)\n",
    "# print(f'Test Loss : {test_avg}')\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
